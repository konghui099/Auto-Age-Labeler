{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyperparameter-tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm4uX65xEWhS",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_Dcux-mEbl2",
        "colab_type": "text"
      },
      "source": [
        "Here, we're going to create our final model. We will use the tree-based feature selection, and a standard scaler. The detailed model architecture can be found in the 'models' module but to give a summary, it has 4 hidden layers and a softmax output layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APht2IDQJCR0",
        "colab_type": "text"
      },
      "source": [
        "Like we did in the baseline model notebook, let's import the necessary modules and load in our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1uplkI9Kmu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "08c57d09-b59f-45d1-9cf0-86b58db8ca8e"
      },
      "source": [
        "# so we have access to the Google Drive filesystem\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcdB6uiEKnvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b437adb-0cc9-4be5-f4d6-5efcddd5e09e"
      },
      "source": [
        "# necessary imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# so we can access local modules within Colab\n",
        "os.chdir('/content/drive/My Drive/auto-age-detector-model')\n",
        "\n",
        "# feature selection defined functions\n",
        "from feature_selection import tree_based_feature_selection\n",
        "\n",
        "# model creation\n",
        "from models import create_model\n",
        "\n",
        "# for feature scaling\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yb7AfGUK082",
        "colab_type": "text"
      },
      "source": [
        "We load in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKIIWjLwKxIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('data/audio_training_data_cleaned.csv').drop(columns=['Unnamed: 0','filename'])\n",
        "# drop any null values we may have forgotten\n",
        "df_train = df_train.dropna(how='any',axis=0)\n",
        "X_train = df_train.drop(columns=['age'],axis=1)\n",
        "y_train = df_train['age']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI0aiHL9NTr7",
        "colab_type": "text"
      },
      "source": [
        "Now we use our tree-based feature selector to select the most important features for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08TVZ0gcRJxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,data_transformer = tree_based_feature_selection(X_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0GHiEZTK9A8",
        "colab_type": "text"
      },
      "source": [
        "We one hot encode the outputs as we did before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EopKWYTPK8ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replaced = {'teens':0,'twenties':1,'thirties':2,'fourties':3,'fifties':4,\n",
        "            'sixties':5,'seventies':6,'eighties':7}\n",
        "\n",
        "# https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-1-hot-encoded-numpy-array\n",
        "\n",
        "# need to put one hot encoded in keras model\n",
        "y_train_ohe = y_train.replace(replaced)\n",
        "y_train_ohe = np.eye(np.max(y_train_ohe)+1)[y_train_ohe]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnTWrXRATDt-",
        "colab_type": "text"
      },
      "source": [
        "Now, we use random search to try out some different hyperparameters. We will focus on finding the right hyperparameters for the dropout and the learning rate. We will use 5-fold cross validation to validate these hyperparameters.\n",
        "\n",
        "We will be using Adam optimization, as it's generally regarded as the SOA optimizer for deep learning problems.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP3Wn0kmS-kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "clf = KerasClassifier(build_fn=create_model,verbose=True)\n",
        "scaler = StandardScaler()\n",
        "param_grid = {\n",
        "    'clf__epochs':[35],\n",
        "    'clf__dropout':[0.1,0.2],\n",
        "    'clf__learning_rate':[0.0001,0.001,0.01]\n",
        "}\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocess',scaler),\n",
        "    ('clf',clf)\n",
        "])\n",
        "\n",
        "# 5 fold cross validation\n",
        "rscv = RandomizedSearchCV(pipeline,param_distributions=param_grid,cv=5,n_iter=3)\n",
        "rscv.fit(X_train,y_train_ohe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6dlDXRUe1c1",
        "colab_type": "text"
      },
      "source": [
        "The output is omitted because there were many run-throughs and random searches, but the final model with the best hyperparameters are created in the 'final-model' notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk33t678fQvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}